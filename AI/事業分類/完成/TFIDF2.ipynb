{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "m = MeCab.Tagger('-d /usr/lib/mecab/dic/mecab-ipadic-neologd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_df = pd.read_csv('example.csv',encoding=\"utf8\") \n",
    "len(csv_df)\n",
    "csv_df.info()\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaconv\n",
    "wakatis = []\n",
    "words = []\n",
    "for w in csv_df['歳出事業']:\n",
    "    words1 = []\n",
    "    w = jaconv.z2h(w, digit=True, ascii=True) # 半角、小文字に統一\n",
    "    for c in m.parse(w).splitlines()[:-1]:  #事業名を分割し解析結果を配列にして繰り返す\n",
    "        surface, feature = c.split('\\t')    #分割された事業名と結果をそれぞれ格納 \n",
    "        if '名詞' in feature:             #名詞ならそれをwords1に追加\n",
    "            if surface != '推進事業' and surface != '事業':\n",
    "                if surface == '健康診査':\n",
    "                    words1.append('健康')\n",
    "                    words1.append('診査')\n",
    "                elif surface == '庄内地域':\n",
    "                    words1.append('庄内')\n",
    "                    words1.append('地域')\n",
    "                else:\n",
    "                    words1.append(surface)\n",
    "            \n",
    "                \n",
    "    str1 = ' '.join(words1) #分割された事業名を空白で区切る\n",
    "    wakatis.append(str1)    #区切られた事業名を配列に格納\n",
    "    words.append(words1)\n",
    "# wakatis\n",
    "csv_df['wakati'] = wakatis\n",
    "learn_df = csv_df[['歳出事業コード','歳出事業','wakati']]\n",
    "learn_df.info()\n",
    "learn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tf = vectorizer.fit_transform(wakatis) # 単語の出現頻度を計算\n",
    "tfidf = transformer.fit_transform(tf)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    word = input('検索:')\n",
    "    if word == '終了':\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        t1 = time.time()\n",
    "        words2 = []\n",
    "        for c in m.parse(word).splitlines()[:-1]:\n",
    "            surface, feature = c.split('\\t')    #分割された事業名と結果をそれぞれ格納 \n",
    "            if '名詞' in feature:\n",
    "                words2.append(surface)\n",
    "        str2 = ' '.join(words2) #分割された事業名を空白で区切る\n",
    "        wakatis.append(str2)\n",
    "        sample_tf = vectorizer.transform([wakatis[-1]])\n",
    "        sample_tfidf = transformer.transform(sample_tf)\n",
    "        similarity = cosine_similarity(sample_tfidf, tfidf)[0]\n",
    "        topn_indices = np.argsort(similarity)[::-1][0:10]\n",
    "        b = True\n",
    "        for sim, tweet in zip(similarity[topn_indices], np.array(csv_df['歳出事業'])[topn_indices]):\n",
    "            if sim != 0:\n",
    "                print(\"({:}): {}\".format(sim, \"\".join(tweet.split())))\n",
    "                b = False\n",
    "            if b:\n",
    "                print('検索結果なし')\n",
    "                break\n",
    "        del wakatis[-1]\n",
    "        print('検索時間:', time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
