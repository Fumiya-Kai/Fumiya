{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_df = pd.read_csv('H28.csv',encoding=\"utf8\") \n",
    "len(csv_df)\n",
    "csv_df.info()\n",
    "csv_df.head()\n",
    "\n",
    "csv_df2 = pd.read_csv('H29.csv',encoding=\"utf8\") \n",
    "len(csv_df2)\n",
    "csv_df2.info()\n",
    "csv_df2.head()\n",
    "\n",
    "csv_df3 = pd.read_csv('H30.csv',encoding=\"utf8\") \n",
    "len(csv_df3)\n",
    "csv_df3.info()\n",
    "csv_df3.head()\n",
    "\n",
    "csv_df4 = pd.read_csv('R1.csv',encoding=\"utf8\") \n",
    "len(csv_df4)\n",
    "csv_df4.info()\n",
    "csv_df4.head()\n",
    "\n",
    "csv_df5 = pd.read_csv('R2.csv',encoding=\"utf8\") \n",
    "len(csv_df5)\n",
    "csv_df5.info()\n",
    "csv_df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#関数の定義\n",
    "#データのスケール変換の関数（０〜１のスケールに変換）\n",
    "def scaler(array):\n",
    "    \n",
    "    M = max(array)\n",
    "    m = min(array)\n",
    "    if M != m:\n",
    "        scaled_array = (array - m*np.ones(shape = array.shape))/(M - m)\n",
    "        def f(x):\n",
    "            return (x - m)/(M - m)\n",
    "    else:\n",
    "        scaled_array = array - m*np.ones(shape = array.shape)\n",
    "        def f(x):   \n",
    "            return x - m\n",
    "#scaled_arrayは変換後のデータ,fは個別に値が与えられた時にscaled_arrayのデータと同様に変換するための関数            \n",
    "    return scaled_array, f\n",
    "\n",
    "#データの前処理の関数\n",
    "def preprocessing(x):\n",
    "    xl = []\n",
    "    prpl = []\n",
    "    for i in range(len(x.T)):\n",
    "        l = scaler(x.T[i])[0]\n",
    "        prpl.append(scaler(x.T[i])[1])\n",
    "        xl.append(l)\n",
    "    \n",
    "    return np.array(xl).T, prpl #np.array(xl).Tは前処理後のデータ,prplは各項目のスケールに合わせるための関数を格納した配列\n",
    "\n",
    "#最も近い値に値を変換する関数\n",
    "#モデルから出力された値を最も近い実際の地目コードに変換する\n",
    "def nearvalue(x, l):\n",
    "    d = []\n",
    "    for i in range(len(l)):\n",
    "        d.append(abs(x-l[i]))\n",
    "        \n",
    "    return l[d.index(min(d))]\n",
    "\n",
    "#決定係数を計算する関数\n",
    "#決定係数を求めるメソッドがないモデルなどの検証に使う\n",
    "def r_2(v, w):\n",
    "    \n",
    "    s1 = np.sum((v-w)**2)\n",
    "    s2 = np.sum((v-np.mean(v))**2)\n",
    "    \n",
    "    return 1-(s1/s2)\n",
    "\n",
    "#正解率を計算する関数\n",
    "#地目コードとの一致率を計算するメソッドがないモデルなどの検証に使う\n",
    "def accuracy(v,w):\n",
    "    u = v-w\n",
    "    a = 0\n",
    "    for d in u:\n",
    "        if d != 0:\n",
    "            a+=1\n",
    "            \n",
    "    return 1-(a/len(u))\n",
    "\n",
    "def d_index(v,w):\n",
    "    u = v-w\n",
    "    a = []\n",
    "    b = []\n",
    "    for i in range(len(u)):\n",
    "        if u[i] != 0:\n",
    "            a.append(i)\n",
    "        else:\n",
    "            b.append(i)\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの前処理のプログラム\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "ev = csv_df.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev2 = csv_df2.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev3 = csv_df3.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev4 = csv_df4.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev5 = csv_df5.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "\n",
    "x_H28 = np.array(ev.values)\n",
    "y_H28 = np.array(csv_df['現況地目コード'].values)\n",
    "x_H29 = np.array(ev2.values)\n",
    "y_H29 = np.array(csv_df2['現況地目コード'].values)\n",
    "x_H30 = np.array(ev3.values)\n",
    "y_H30 = np.array(csv_df3['現況地目コード'].values)\n",
    "x_R1 = np.array(ev4.values)\n",
    "y_R1 = np.array(csv_df4['現況地目コード'].values)\n",
    "x_R2 = np.array(ev5.values)\n",
    "y_R2 = np.array(csv_df5['現況地目コード'].values)\n",
    "\n",
    "x =np.concatenate([x_H28, x_H29])\n",
    "x =np.concatenate([x, x_H30])\n",
    "x =np.concatenate([x, x_R1])\n",
    "x =np.concatenate([x, x_R2])\n",
    "y =np.concatenate([y_H28, y_H29])\n",
    "y =np.concatenate([y, y_H30])\n",
    "y =np.concatenate([y, y_R1])\n",
    "y =np.concatenate([y, y_R2])\n",
    "y_class = list(set(y))\n",
    "\n",
    "prpx = preprocessing(x)[1]\n",
    "x = preprocessing(x)[0]\n",
    "x_H28 = x[0:len(x_H28)]\n",
    "x_H29 = x[len(x_H28):len(x_H28)+len(x_H29)]\n",
    "x_H30 = x[len(x_H28)+len(x_H29):len(x_H28)+len(x_H29)+len(x_H30)]\n",
    "x_R1 = x[len(x_H28)+len(x_H29)+len(x_H30):len(x_H28)+len(x_H29)+len(x_H30)+len(x_R1)]\n",
    "x_R2 = x[len(x_H28)+len(x_H29)+len(x_H30)+len(x_R1):]\n",
    "\n",
    "y_H28 = y_H28[np.argsort(x_H28[:,0])]\n",
    "y_H29 = y_H29[np.argsort(x_H29[:,0])]\n",
    "y_H30 = y_H30[np.argsort(x_H30[:,0])]\n",
    "y_R1 = y_R1[np.argsort(x_R1[:,0])]\n",
    "y_R2 = y_R2[np.argsort(x_R2[:,0])]\n",
    "\n",
    "x_H28 = x_H28[np.argsort(x_H28[:,0])]\n",
    "x_H29 = x_H29[np.argsort(x_H29[:,0])]\n",
    "x_H30 = x_H30[np.argsort(x_H30[:,0])]\n",
    "x_R1 = x_R1[np.argsort(x_R1[:,0])]\n",
    "x_R2 = x_R2[np.argsort(x_R2[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H28を学習してH29をテスト\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "x_train = x_H28\n",
    "y_train = y_H29[:len(x_train)]\n",
    "\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "print(pd.DataFrame({\"Name\":ev.columns,\n",
    "                    \"Coefficients\":np.abs(lr.coef_)}).sort_values(by='Coefficients') )\n",
    "print(lr.intercept_)\n",
    "\n",
    "x_test = x_H29\n",
    "y_test = y_H30[:len(x_H29)]\n",
    "\n",
    "y_tr_predict = [nearvalue(i, y_class) for i in lr.predict(x_train)]\n",
    "y_predict = [nearvalue(i, y_class) for i in lr.predict(x_test)]\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "r2_1 = r_2(y_predict, y_test)\n",
    "accuracy1 = accuracy(y_predict,y_test)\n",
    "print(f\"決定係数{r2_1}\")\n",
    "print(f\"正解率{accuracy1}\")\n",
    "\n",
    "#predicted = lr.predict(x2)\n",
    "\n",
    "#print(\"classification report\")\n",
    "#print(sklearn.metrics.classification_report(y2, predicted))\n",
    "\n",
    "print('MSE train data: ', np.sqrt(mean_squared_error(y_train, y_tr_predict))) # 学習データを用いたときの平均二乗誤差を出力\n",
    "print('MSE test data: ', np.sqrt(mean_squared_error(y_test, y_predict)))         # 検証データを用いたときの平均二乗誤差を出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H28とH29のデータを学習しH30をテスト\n",
    "lr2 = LinearRegression()\n",
    "\n",
    "x_train2 = np.concatenate([x_train,x_test])\n",
    "y_train2 = np.concatenate([y_train,y_test])\n",
    "\n",
    "lr2.fit(x_train2, y_train2)\n",
    "\n",
    "print(pd.DataFrame({\"Name\":ev2.columns,\n",
    "                    \"Coefficients\":np.abs(lr2.coef_)}).sort_values(by='Coefficients') )\n",
    "print(lr2.intercept_)\n",
    "\n",
    "x_test2 = x_H30\n",
    "y_test2 = y_H30[:len(x_H30)]\n",
    "\n",
    "y_tr_predict2 = [nearvalue(i, y_class) for i in lr2.predict(x_train2)]\n",
    "y_predict2 = [nearvalue(i, y_class) for i in lr2.predict(x_test2)]\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "r2_2 = r_2(y_predict2, y_test2)\n",
    "accuracy2 = accuracy(y_predict2,y_test2)\n",
    "print(f\"決定係数{r2_2}\")\n",
    "print(f\"正解率{accuracy2}\")\n",
    "\n",
    "\n",
    "print('MSE train data: ', np.sqrt(mean_squared_error(y_train2, y_tr_predict2))) # 学習データを用いたときの平均二乗誤差を出力\n",
    "print('MSE test data: ', np.sqrt(mean_squared_error(y_test2, y_predict2)))         # 検証データを用いたときの平均二乗誤差を出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H28~H30のデータを学習しR1をテスト\n",
    "lr3 = LinearRegression()\n",
    "\n",
    "x_train3 = np.concatenate([x_train2,x_test2])\n",
    "y_train3 = np.concatenate([y_train2,y_test2])\n",
    "\n",
    "lr3.fit(x_train3, y_train3)\n",
    "\n",
    "print(pd.DataFrame({\"Name\":ev3.columns,\n",
    "                    \"Coefficients\":np.abs(lr3.coef_)}).sort_values(by='Coefficients') )\n",
    "print(lr3.intercept_)\n",
    "\n",
    "x_test3 = x_R1\n",
    "y_test3 = y_R2[:len(x_R1)]\n",
    "\n",
    "y_tr_predict3 = [nearvalue(i, y_class) for i in lr3.predict(x_train3)]\n",
    "y_predict3 = [nearvalue(i, y_class) for i in lr3.predict(x_test3)]\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "r2_3 = r_2(y_predict3, y_test3)\n",
    "accuracy3 = accuracy(y_predict3,y_test3)\n",
    "print(f\"決定係数{r2_3}\")\n",
    "print(f\"正解率{accuracy3}\")\n",
    "\n",
    "\n",
    "print('MSE train data: ', np.sqrt(mean_squared_error(y_train3, y_tr_predict3))) # 学習データを用いたときの平均二乗誤差を出力\n",
    "print('MSE test data: ', np.sqrt(mean_squared_error(y_test3, y_predict3)))         # 検証データを用いたときの平均二乗誤差を出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
