{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの読み込み\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "csv_df = pd.read_csv('H28.csv',encoding=\"utf8\") \n",
    "len(csv_df)\n",
    "csv_df.info()\n",
    "csv_df.head()\n",
    "\n",
    "csv_df2 = pd.read_csv('H29.csv',encoding=\"utf8\") \n",
    "len(csv_df2)\n",
    "csv_df2.info()\n",
    "csv_df2.head()\n",
    "\n",
    "csv_df3 = pd.read_csv('H30.csv',encoding=\"utf8\") \n",
    "len(csv_df3)\n",
    "csv_df3.info()\n",
    "csv_df3.head()\n",
    "\n",
    "csv_df4 = pd.read_csv('R1.csv',encoding=\"utf8\") \n",
    "len(csv_df4)\n",
    "csv_df4.info()\n",
    "csv_df4.head()\n",
    "\n",
    "csv_df5 = pd.read_csv('R2.csv',encoding=\"utf8\") \n",
    "len(csv_df5)\n",
    "csv_df5.info()\n",
    "csv_df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#関数の定義\n",
    "#データのスケール変換の関数（０〜１のスケールに変換）\n",
    "def scaler(array):\n",
    "    \n",
    "    M = max(array)\n",
    "    m = min(array)\n",
    "    if M != m:\n",
    "        scaled_array = (array - m*np.ones(shape = array.shape))/(M - m)\n",
    "        def f(x):\n",
    "            return (x - m)/(M - m)\n",
    "    else:\n",
    "        scaled_array = array - m*np.ones(shape = array.shape)\n",
    "        def f(x):   \n",
    "            return x - m\n",
    "#scaled_arrayは変換後のデータ,fは個別に値が与えられた時にscaled_arrayのデータと同様に変換するための関数            \n",
    "    return scaled_array, f\n",
    "\n",
    "#データの前処理の関数\n",
    "def preprocessing(x):\n",
    "    xl = []\n",
    "    prpl = []\n",
    "    for i in range(len(x.T)):\n",
    "        l = scaler(x.T[i])[0]\n",
    "        prpl.append(scaler(x.T[i])[1])\n",
    "        xl.append(l)\n",
    "    \n",
    "    return np.array(xl).T, prpl #np.array(xl).Tは前処理後のデータ,prplは各項目のスケールに合わせるための関数を格納した配列\n",
    "\n",
    "#最も近い値に値を変換する関数\n",
    "#モデルから出力された値を最も近い実際の地目コードに変換する\n",
    "def nearvalue(x, l):\n",
    "    d = []\n",
    "    for i in range(len(l)):\n",
    "        d.append(abs(x-l[i]))\n",
    "        \n",
    "    return l[d.index(min(d))]\n",
    "\n",
    "#決定係数を計算する関数\n",
    "#決定係数を求めるメソッドがないモデルなどの検証に使う\n",
    "def r_2(v, w):\n",
    "    \n",
    "    s1 = np.sum((v-w)**2)\n",
    "    s2 = np.sum((v-np.mean(v))**2)\n",
    "    \n",
    "    return 1-(s1/s2)\n",
    "\n",
    "#正解率を計算する関数\n",
    "#地目コードとの一致率を計算するメソッドがないモデルなどの検証に使う\n",
    "def accuracy(v,w):\n",
    "    u = v-w\n",
    "    a = 0\n",
    "    for d in u:\n",
    "        if d != 0:\n",
    "            a+=1\n",
    "            \n",
    "    return 1-(a/len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの前処理のプログラム\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "ev = csv_df.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev2 = csv_df2.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev3 = csv_df3.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev4 = csv_df4.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev5 = csv_df5.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "\n",
    "x_H28 = np.array(ev.values)\n",
    "y_H28 = np.array(csv_df['現況地目コード'].values)\n",
    "x_H29 = np.array(ev2.values)\n",
    "y_H29 = np.array(csv_df2['現況地目コード'].values)\n",
    "x_H30 = np.array(ev3.values)\n",
    "y_H30 = np.array(csv_df3['現況地目コード'].values)\n",
    "x_R1 = np.array(ev4.values)\n",
    "y_R1 = np.array(csv_df4['現況地目コード'].values)\n",
    "x_R2 = np.array(ev5.values)\n",
    "y_R2 = np.array(csv_df5['現況地目コード'].values)\n",
    "\n",
    "x =np.concatenate([x_H28, x_H29])\n",
    "x =np.concatenate([x, x_H30])\n",
    "x =np.concatenate([x, x_R1])\n",
    "x =np.concatenate([x, x_R2])\n",
    "y =np.concatenate([y_H28, y_H29])\n",
    "y =np.concatenate([y, y_H30])\n",
    "y =np.concatenate([y, y_R1])\n",
    "y =np.concatenate([y, y_R2])\n",
    "y_class = list(set(y))\n",
    "\n",
    "prpx = preprocessing(x)[1]\n",
    "x = preprocessing(x)[0]\n",
    "x_H28 = x[0:len(x_H28)]\n",
    "x_H29 = x[len(x_H28):len(x_H28)+len(x_H29)]\n",
    "x_H30 = x[len(x_H28)+len(x_H29):len(x_H28)+len(x_H29)+len(x_H30)]\n",
    "x_R1 = x[len(x_H28)+len(x_H29)+len(x_H30):len(x_H28)+len(x_H29)+len(x_H30)+len(x_R1)]\n",
    "x_R2 = x[len(x_H28)+len(x_H29)+len(x_H30)+len(x_R1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neural_network\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "\n",
    "x1 = x_H28[np.argsort(x_H28[:,0])]\n",
    "x2 = x_H29[np.argsort(x_H29[:,0])]\n",
    "x3 = x_H30[np.argsort(x_H30[:,0])]\n",
    "x4 = x_R1[np.argsort(x_R1[:,0])]\n",
    "x_train = np.concatenate([x1,x2])\n",
    "x_train = np.concatenate([x_train,x3])\n",
    "\n",
    "y1 = y_H29[np.argsort(x_H29[:,0])][:len(x1)]\n",
    "y2 = y_H30[np.argsort(x_H30[:,0])][:len(x2)]\n",
    "y3 = y_R1[np.argsort(x_H30[:,0])][:len(x3)]\n",
    "y_train = np.concatenate([y1,y2])\n",
    "y_train = np.concatenate([y_train,y3])\n",
    "\n",
    "clf = neural_network.MLPRegressor(activation=\"logistic\", alpha=0.0001)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "def f(n):\n",
    "    \n",
    "    n = prpx[0](n)\n",
    "\n",
    "    i = np.where(x_R1.T[0]==n)\n",
    "    x_test = [x_R1[i[0][0]]]\n",
    "    i = np.where(x_R2.T[0]==n)\n",
    "    y_test = [y_R2[i[0][0]]]\n",
    " \n",
    " #    y_tr_predict = np.array([nearvalue(i, y_class) for i in clf.predict(x_train)])\n",
    "    y_predict = np.array([nearvalue(i, y_class) for i in clf.predict(x_test)])\n",
    "    \n",
    "    return y_test, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = []\n",
    "al = []\n",
    "for n in np.array(ev4.values).T[0]:\n",
    "    al.append(f(n)[0][0])\n",
    "    pl.append(f(n)[1][0])\n",
    "    \n",
    "pl = np.array(pl)\n",
    "al = np.array(al)\n",
    "print(f'決定係数{r_2(al,pl)}')\n",
    "print(f'正解率{accuracy(pl,al)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
