{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_df = pd.read_csv('H28.csv',encoding=\"utf8\") \n",
    "len(csv_df)\n",
    "csv_df.info()\n",
    "csv_df.head()\n",
    "\n",
    "csv_df2 = pd.read_csv('H29.csv',encoding=\"utf8\") \n",
    "len(csv_df2)\n",
    "csv_df2.info()\n",
    "csv_df2.head()\n",
    "\n",
    "csv_df3 = pd.read_csv('H30.csv',encoding=\"utf8\") \n",
    "len(csv_df3)\n",
    "csv_df3.info()\n",
    "csv_df3.head()\n",
    "\n",
    "csv_df4 = pd.read_csv('R1.csv',encoding=\"utf8\") \n",
    "len(csv_df4)\n",
    "csv_df4.info()\n",
    "csv_df4.head()\n",
    "\n",
    "csv_df5 = pd.read_csv('R2.csv',encoding=\"utf8\") \n",
    "len(csv_df5)\n",
    "csv_df5.info()\n",
    "csv_df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(array, min_scale, max_scale):\n",
    "    \n",
    "    M = max(array)\n",
    "    m = min(array)\n",
    "    if M != m:\n",
    "        scaled_array = (array - m*np.ones(shape = array.shape))/(M - m)\n",
    "    else:\n",
    "        scaled_array = array - m*np.ones(shape = array.shape)\n",
    "    \n",
    "    return scaled_array\n",
    "\n",
    "def preprocessing(x):\n",
    "    xl = []\n",
    "    for i in range(len(x.T)):\n",
    "        l = scaler(x.T[i], 0, 1)\n",
    "        xl.append(l)\n",
    "    \n",
    "    return np.array(xl).T\n",
    "\n",
    "def nearvalue(x, l):\n",
    "    d = []\n",
    "    for i in range(len(l)):\n",
    "        d.append(abs(x-l[i]))\n",
    "        \n",
    "    return l[d.index(min(d))]\n",
    "\n",
    "def r_2(v, w):\n",
    "    \n",
    "    s1 = np.sum((v-w)**2)\n",
    "    s2 = np.sum((v-np.mean(v))**2)\n",
    "    \n",
    "    return 1-(s1/s2)\n",
    "\n",
    "def accuracy(v,w):\n",
    "    u = v-w\n",
    "    a = 0\n",
    "    for d in u:\n",
    "        if d != 0:\n",
    "            a+=1\n",
    "            \n",
    "    return 1-(a/len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "ev = csv_df.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev2 = csv_df2.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev3 = csv_df3.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev4 = csv_df4.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "ev5 = csv_df5.drop(columns =['所在大字', '所在本番', '所在枝番', '所在小枝番', '所在地番区分',\n",
    "                           '所在地番分割', '所在小字', '現況地目コード'])\n",
    "\n",
    "x_H28 = np.array(ev.values)\n",
    "y_H28 = np.array(csv_df['現況地目コード'].values)\n",
    "x_H29 = np.array(ev2.values)\n",
    "y_H29 = np.array(csv_df2['現況地目コード'].values)\n",
    "x_H30 = np.array(ev3.values)\n",
    "y_H30 = np.array(csv_df3['現況地目コード'].values)\n",
    "x_R1 = np.array(ev4.values)\n",
    "y_R1 = np.array(csv_df4['現況地目コード'].values)\n",
    "x_R2 = np.array(ev5.values)\n",
    "y_R2 = np.array(csv_df5['現況地目コード'].values)\n",
    "\n",
    "x =np.concatenate([x_H28, x_H29])\n",
    "x =np.concatenate([x, x_H30])\n",
    "x =np.concatenate([x, x_R1])\n",
    "x =np.concatenate([x, x_R2])\n",
    "y =np.concatenate([y_H28, y_H29])\n",
    "y =np.concatenate([y, y_H30])\n",
    "y =np.concatenate([y, y_R1])\n",
    "y =np.concatenate([y, y_R2])\n",
    "y_class = list(set(y))\n",
    "\n",
    "x = preprocessing(x)\n",
    "x_H28 = x[0:len(x_H28)]\n",
    "x_H29 = x[len(x_H28):len(x_H28)+len(x_H29)]\n",
    "x_H30 = x[len(x_H28)+len(x_H29):len(x_H28)+len(x_H29)+len(x_H30)]\n",
    "x_R1 = x[len(x_H28)+len(x_H29)+len(x_H30):len(x_H28)+len(x_H29)+len(x_H30)+len(x_R1)]\n",
    "x_R2 = x[len(x_H28)+len(x_H29)+len(x_H30)+len(x_R1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特徴選択\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "def feature_selection(x_train,y_train,x_test,k):\n",
    "    selector = SelectKBest(k=k, score_func=mutual_info_classif)\n",
    "    selector.fit(x_train,y_train)\n",
    "    x_train_new = selector.transform(x_train)\n",
    "    x_test_new = selector.transform(x_test)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(x_train_new.shape)\n",
    "    print(x_test_new.shape)\n",
    "    \n",
    "    return x_train_new, x_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H28を学習しH29をテスト\n",
    "x_train = x_H28\n",
    "y_train = y_H28\n",
    "x_test = x_H29\n",
    "y_test = y_H29\n",
    "\n",
    "x_train, x_test = feature_selection(x_train,y_train,x_test,10)\n",
    "\n",
    "from sklearn import neural_network\n",
    "clf = neural_network.MLPRegressor(activation=\"logistic\", alpha=0.0001, max_iter=1000)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_tr_predict = np.array([nearvalue(i, y_class) for i in clf.predict(x_train)])\n",
    "y_predict = np.array([nearvalue(i, y_class) for i in clf.predict(x_test)])\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "r2_1 = r_2(y_test, y_predict)\n",
    "accuracy1 = accuracy(y_predict,y_test)\n",
    "print(f\"決定係数{r2_1}\")\n",
    "print(f\"正解率{accuracy1}\")\n",
    "\n",
    "accuracy1 = clf.score(x_test, y_test)\n",
    "print(f\"決定係数{accuracy1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(\"classification report\")\n",
    "#print(sklearn.metrics.classification_report(y_test, predicted))\n",
    "\n",
    "t2 =time.time() - start\n",
    "print(\"かかった時間\")\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H28とH29を学習しH30をテスト\n",
    "x_train2 = np.concatenate([x_H28, x_H29])\n",
    "y_train2 = np.concatenate([y_H28, y_H29])\n",
    "x_test2 = x_H30\n",
    "y_test2 = y_H30\n",
    "\n",
    "x_train, x_test = feature_selection(x_train,y_train,x_test,10)\n",
    "\n",
    "from sklearn import neural_network\n",
    "clf2 = neural_network.MLPRegressor(activation=\"logistic\", alpha=0.0001, max_iter=1000)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "clf2.fit(x_train2, y_train2)\n",
    "\n",
    "y_tr_predict2 = np.array([nearvalue(i, y_class) for i in clf2.predict(x_train2)])\n",
    "y_predict2 = np.array([nearvalue(i, y_class) for i in clf2.predict(x_test2)])\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "r2_2 = r_2(y_test2, y_predict2)\n",
    "accuracy2 = accuracy(y_test2,y_predict2)\n",
    "print(f\"決定係数{r2_2}\")\n",
    "print(f\"正解率{accuracy2}\")\n",
    "\n",
    "accuracy2 = clf2.score(x_test2, y_test2)\n",
    "print(f\"決定係数{accuracy2}\")\n",
    "\n",
    "#predicted2 = clf2.predict(x_test2)\n",
    "\n",
    "#print(\"classification report\")\n",
    "#print(sklearn.metrics.classification_report(y_test2, predicted2))\n",
    "\n",
    "t2 =time.time() - start\n",
    "print(\"かかった時間\")\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
